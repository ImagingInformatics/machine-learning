{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Another simple notebook example.\n",
        "\n",
        "Here we are using the CIFAR dataset:\n",
        "    \n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "    \n",
        "*\"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.*\n",
        "\n",
        "*The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\"*\n",
        "\n",
        "We will explore utilizing both a more conventional CNN, as well as a residual network based architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#As usual we start by importing the necessary modules\n",
        "from keras.models import Sequential, Model\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Dense, Activation, Flatten, Input, Add, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from IPython.display import SVG\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data\n",
        "\n",
        "Note that we have subsampled the data. Try testing different sampling strategies... or train on the entire dataset.\n",
        "\n",
        "Ask yourself, how does this affect performance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "nb_classes = 10\n",
        "nb_epoch = 20\n",
        "nb_filter = 10\n",
        "\n",
        "img_rows, img_cols = 32, 32\n",
        "img_channels = 3\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#subsample to speed up training (remove following four lines to try training on everything)\n",
        "X_train = X_train[0::10,:,:,:] #every 10 examples for train\n",
        "y_train = y_train[0::10]\n",
        "X_test = X_test[0::5,:,:,:] #every 5 example for test (i.e. validation)\n",
        "y_test = y_test[0::5]\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define basic CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(nb_filter, (3, 3), input_shape=(img_rows, img_cols, img_channels),\n",
        "                 padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(nb_filter, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(nb_filter, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(nb_filter, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(nb_filter, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dense(nb_classes, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr = 1.E-3),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define resnet type architecture\n",
        "\n",
        "Note the addition of the line:\n",
        "    \n",
        "```python\n",
        "x = Add()([x, y])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_img = Input(shape=(img_rows, img_cols, img_channels))\n",
        "x = Conv2D(nb_filter, (3, 3), padding=\"same\", activation=\"relu\")(in_img)\n",
        "for _ in range(2):\n",
        "    y = Conv2D(nb_filter, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    y = Conv2D(nb_filter, (3, 3), padding=\"same\")(y)\n",
        "    x = Add()([x, y])\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dense(nb_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "residual = Model(inputs=in_img, outputs=x)\n",
        "\n",
        "residual.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr = 1.E-3),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the basic CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn = model.fit(X_train, Y_train, batch_size=batch_size,\n",
        "                epochs=nb_epoch, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the resnet type model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "resi = residual.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the learning curves for both models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "x = range(nb_epoch)\n",
        "plt.plot(x, cnn.history['accuracy'], label=\"cnn train\")\n",
        "plt.plot(x, cnn.history['val_accuracy'], label=\"cnn val\")\n",
        "plt.plot(x, resi.history['accuracy'], label=\"resi train\")\n",
        "plt.plot(x, resi.history['val_accuracy'], label=\"resi val\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x, cnn.history['loss'], label=\"cnn train\")\n",
        "plt.plot(x, cnn.history['val_loss'], label=\"cnn val\")\n",
        "plt.plot(x, resi.history['loss'], label=\"resi train\")\n",
        "plt.plot(x, resi.history['val_loss'], label=\"resi val\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now try visualizing the test set images and the classifications that the network made (similar to what we did in the MNist example).\n",
        "\n",
        "Other things to try:\n",
        "    - Train the networks longer\n",
        "    - Increase the network learning rate\n",
        "    - Increase the number of filters in each convolution layer\n",
        "    - Add regularization (e.g., dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
